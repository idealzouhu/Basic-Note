### 高性能

#### 超大文件中在有限的内存里找到单词频率

问题： 有 n （n>1000）多个文件，文件里存储了大量单词数据。如何快速统计每个独特单词出现的次数。  要求在读取过程中，能实时输出每个单词当前的数量。可以手动终止读取程序，终止后输出所有已统计到的单词数量。

解决措施有：

- HashMap 保存单词及其数量

- 多线程并发处理，使用 ConcurrentHashMap 保证线程安全性。
- 为了最大化线程的使用，可以将文件分块

问题进阶：返回出现频率最高的 100 个单词

- 使用小顶堆保存 HashMap 中频率出现最高的

[超大文件中在有限的内存里找到单词频率 top 100_1g内存,500g的文件,如何获取出现最多的单词-CSDN博客](https://blog.csdn.net/weixin_59287292/article/details/123242183)







### 接口优化

- 线程池
- 异步任务，比如延时队列





### 海量数据

[海量数据处理常见问题](https://gitcode.com/doocs/advanced-java/overview)

